services:
#  app:
#    restart: always
#    container_name: app-dev
#    image: app-dev
#    build:
#      context: dashboard
#      target: development
#    volumes:
#      - ./src:/app/src
#    ports:
#      - 4000:3000
  postgres:
    restart: on-failure
    image: postgres:15
    environment:
      POSTGRES_DB: conversation
      POSTGRES_USER: ${PG_USER}
      POSTGRES_PASSWORD: ${PG_PASSWORD}
#    ports:
#      - '5432:5432'
  backend:
    restart: always
    depends_on:
      - postgres
    volumes:
      - /tmp:/tmp
    #    command:
    #      - /bin/sh
    #      - -c
    #      - sleep 1; npm run migration:run; node main.js
    environment:
      DB_NAME: conversation
      DB_HOST: postgres
      DB_PORT: "5432"
      DB_USERNAME: ${PG_USER}
      DB_PASSWORD: ${PG_PASSWORD}
      RABBIT_HOST: rabbitmq
      RABBIT_PORT: 5672
      RECOGNITION_HOST: ml
      RECOGNITION_PORT: 3333
      FILE_STORAGE_LOCAL: "true"
      FILE_STORAGE_DIR: /tmp
      RULE_MODEL_HOST: ml-chat
      RULE_MODEL_PORT: 4444
      RULE_MODEL_ENDPOINT: rule_based_text
      DEFAULT_MODEL_HOST: ml-chat
      DEFAULT_MODEL_PORT: 4444
      DEFAULT_MODEL_ENDPOINT: text
    image: banzai/audio-service:v0.0.1
    build:
      context: backend/audio-service
      dockerfile: Dockerfile
    ports:
      - '3000:3000'
      - '3002:3001'
  ml:
    restart: always
    volumes:
      - app:/root/.cache
      - /tmp:/tmp
    image: banzai/predictor-ml:v0.0.1
    build:
      context: ml
      dockerfile: Dockerfile
    ports:
      - '3001:3333'
  ml-chat:
    restart: always
    environment:
      BACKEND_HOST: backend
      BACKEND_PORT: 3000
    volumes:
      - /tmp:/tmp
      - app:/root/.cache
      - ./data:/data
    image: banzai/predictor-ml-chat:v0.0.1
    build:
      context: ml-chat
      dockerfile: Dockerfile
    ports:
      - '5001:4444'
volumes:
  app: